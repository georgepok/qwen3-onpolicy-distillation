# Environment Configuration for Qwen3 On-Policy Distillation
# Deployment to pokazge@spark-129a.local (GB10 128GB GPU)

# ============================================================================
# Model Configuration
# ============================================================================

# Student model (smaller model being trained)
STUDENT_MODEL=Qwen/Qwen3-4B-Instruct-2507

# Teacher model (larger model providing guidance)
TEACHER_MODEL=Qwen/Qwen3-32B

# Teacher quantization (fp8 recommended for memory efficiency)
TEACHER_QUANT=fp8

# ============================================================================
# GPU Memory Allocation
# ============================================================================

# Student GPU memory utilization (fraction of total GPU memory)
STUDENT_GPU_MEM=0.2

# Teacher GPU memory utilization (fraction of total GPU memory)
TEACHER_GPU_MEM=0.35

# Maximum sequence length for student model
STUDENT_MAX_LEN=4096

# ============================================================================
# HuggingFace Configuration
# ============================================================================

# HuggingFace cache directory
HF_CACHE_DIR=/home/pokazge/.cache/huggingface

# HuggingFace token (optional)
HF_TOKEN=

# ============================================================================
# Logging & Tracking (Optional)
# ============================================================================

# Weights & Biases API key (optional)
WANDB_API_KEY=

# ============================================================================
# Container Configuration
# ============================================================================

# Container names
VLLM_CONTAINER_NAME=qwen3-vllm-student
SGLANG_CONTAINER_NAME=qwen3-sglang-teacher
TRAINING_CONTAINER_NAME=qwen3-training

# API ports
VLLM_PORT=8000
SGLANG_PORT=30000
