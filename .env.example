# Environment Configuration for Qwen3 On-Policy Distillation
# Copy this file to .env and update values as needed

# ============================================================================
# Model Configuration
# ============================================================================

# Student model (smaller model being trained)
STUDENT_MODEL=Qwen/Qwen3-4B-Instruct-2507

# Teacher model (larger model providing guidance)
TEACHER_MODEL=Qwen/Qwen3-32B

# Teacher quantization (fp8 recommended for memory efficiency)
TEACHER_QUANT=fp8

# ============================================================================
# GPU Memory Allocation
# ============================================================================

# Student GPU memory utilization (fraction of total GPU memory)
# Default: 0.2 (~25GB on 128GB GPU for Qwen3-4B)
STUDENT_GPU_MEM=0.2

# Teacher GPU memory utilization (fraction of total GPU memory)
# Default: 0.35 (~45GB on 128GB GPU for Qwen3-32B with FP8)
TEACHER_GPU_MEM=0.35

# Maximum sequence length for student model
STUDENT_MAX_LEN=4096

# ============================================================================
# HuggingFace Configuration
# ============================================================================

# HuggingFace cache directory (for storing downloaded models)
# This should be on a disk with sufficient space (50GB+ recommended)
HF_CACHE_DIR=~/.cache/huggingface

# HuggingFace token (optional, only needed for gated models)
# Get your token from: https://huggingface.co/settings/tokens
HF_TOKEN=

# ============================================================================
# Logging & Tracking (Optional)
# ============================================================================

# Weights & Biases API key (optional, for experiment tracking)
# Get your key from: https://wandb.ai/authorize
WANDB_API_KEY=

# ============================================================================
# Advanced Configuration (Usually don't need to change)
# ============================================================================

# Container names (used by docker-compose)
VLLM_CONTAINER_NAME=qwen3-vllm-student
SGLANG_CONTAINER_NAME=qwen3-sglang-teacher
TRAINING_CONTAINER_NAME=qwen3-training

# API ports (change if ports are already in use)
VLLM_PORT=8000
SGLANG_PORT=30000

# ============================================================================
# Example Configurations for Different GPU Sizes
# ============================================================================

# For 128GB GPU (GB10, H100):
#   STUDENT_MODEL=Qwen/Qwen3-4B-Instruct-2507
#   TEACHER_MODEL=Qwen/Qwen3-32B
#   STUDENT_GPU_MEM=0.2
#   TEACHER_GPU_MEM=0.35

# For 80GB GPU (A100):
#   STUDENT_MODEL=Qwen/Qwen3-8B
#   TEACHER_MODEL=Qwen/Qwen3-14B
#   STUDENT_GPU_MEM=0.25
#   TEACHER_GPU_MEM=0.35

# For 48GB GPU (A6000, RTX 6000 Ada):
#   STUDENT_MODEL=Qwen/Qwen3-4B-Instruct-2507
#   TEACHER_MODEL=Qwen/Qwen3-8B
#   STUDENT_GPU_MEM=0.15
#   TEACHER_GPU_MEM=0.30
